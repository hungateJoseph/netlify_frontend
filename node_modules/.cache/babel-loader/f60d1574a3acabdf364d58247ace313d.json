{"ast":null,"code":"var _jsxFileName = \"/Users/josephhungate/my-app/src/ProjectOverview.js\";\nimport './App.css';\nimport React from 'react';\nimport { Navigate, Outlet } from 'react-router-dom';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\nexport default function ProjectOverview() {\n  return /*#__PURE__*/_jsxDEV(_Fragment, {\n    children: /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"main-container\",\n      children: /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"about-container\",\n        children: [/*#__PURE__*/_jsxDEV(\"h3\", {\n          children: \"Inspiration\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 13,\n          columnNumber: 9\n        }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n          className: \"about\",\n          children: [\"During his presidency, Donald Trump was such a prolific Tweeter that specific tools were developed to analyze his tweets and alert companies when he tweeted about their stock. Now, out of the 535 sitting Members of the U.S. Congress, only five have inactive Twitter accounts. What correlations can be drawn between their tweets and political activities or events throughout the country? The \", /*#__PURE__*/_jsxDEV(\"a\", {\n            className: \"emphasis\",\n            children: \"Political Tweet Tool\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 18,\n            columnNumber: 85\n          }, this), \" aims to analyze the behavior of politicians' tweets and see what conclusions can be drawn.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 20,\n            columnNumber: 9\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 20,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"h2\", {\n            children: \"Development\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 21,\n            columnNumber: 9\n          }, this), \"I began by creating a Twitter Developer account, which allowed me to utilize the Twitter API for the tweet scraping part of this project. After writing some basic Python to retrieve the 535 Congress twiter handles from the House press gallery website, I was ready to start gathering data.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 24,\n            columnNumber: 9\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 24,\n            columnNumber: 15\n          }, this), \"I used the \", /*#__PURE__*/_jsxDEV(\"a\", {\n            className: \"emphasis\",\n            href: \"https://www.tweepy.org/\",\n            target: \"blank\",\n            children: \"Tweepy\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 25,\n            columnNumber: 20\n          }, this), \" Python library to facilitate the tweet scraping process. I then integrated the Tweepy API with a custom politician data structure that would facilitate both the later SQL filtering and sentiment analysis. As a web-hosted project, only twenty tweets are gathered per congressman/congresswoman in any given day range. This is to reduce loading times for the end user. Larger data sets can be implemented with a direct download of this project from my \", /*#__PURE__*/_jsxDEV(\"a\", {\n            className: \"emphasis\",\n            children: \"Github\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 28,\n            columnNumber: 110\n          }, this), \".\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 29,\n            columnNumber: 9\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 29,\n            columnNumber: 15\n          }, this), \"The resulting dataset contains over 10,000 tweets for any selected date range, which can be further filtered by name, district, state, party, time in office, retweet status, etc.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 32,\n            columnNumber: 9\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 32,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"h2\", {\n            children: \"Sentiment Analysis\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 33,\n            columnNumber: 9\n          }, this), \"I used the \", /*#__PURE__*/_jsxDEV(\"a\", {\n            className: \"emphasis\",\n            href: \"https://www.tweepy.org/\",\n            target: \"blank\",\n            children: \"VADER (Valence Aware Dictionary and sEntiment Reasoner)\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 34,\n            columnNumber: 20\n          }, this), \" analysis tool to establish a baseline sentiment rating for each tweet. Although robust in nature, the VADER lexicon lacked certain key features necessary for an authentic tweet analysis. First, each tweet was cleaned to remove superfluous text such as links and images. Next, I updated the VADER lexicon to include emojis and \\\"@TwitterHandle\\\" references. For example, in the tweet \\\"When is @JosephHungate123 going to take responsibility for the horrible state of this website?\\\" it's necessary for VADER to know that \\\"@JosephHungate123\\\" is a person that the tweeter is assigning blame to.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 39,\n            columnNumber: 9\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 39,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"h2\", {\n            children: \"Analysis\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 40,\n            columnNumber: 9\n          }, this), \"Analysis of the data thus far has shown some interesting results, but a much larger dataset is needed to demonstrate significance. It is clear, however, that as COVID-19 progressed from March to June, the impact of financial news on market activity increased as well. I am not a financial analyst \\u2013 this is merely a project conducted out of curiosity \\u2013 but I would expect that with more retail investors, and with a market making stronger reactionary moves to both financial and non-financial news, overall market efficiency was reduced slightly, leaving significant opportunity to institutional investors willing to trust emerging patterns in news, Twitter, and other online activity.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 47,\n            columnNumber: 9\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 47,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"h2\", {\n            children: \"Notes\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 48,\n            columnNumber: 9\n          }, this), \"The web version of this database was developed out of a passion for digital UI and an interest in presenting somewhat complex financial information in the simplest way possible. A few notes:\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 50,\n            columnNumber: 1\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 50,\n            columnNumber: 7\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 14,\n          columnNumber: 9\n        }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n          className: \"indent\",\n          children: [\"The database only covers market activity (9:30 to 4), as before/after-market data is less consistent and has less retail investor activity. Only companies on the NYSE or Nasdaq exchanges are included in the dataset.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 52,\n            columnNumber: 1\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 52,\n            columnNumber: 7\n          }, this), \"As a general rule, stocks are shown for a given day only if they demonstrated increased trading volume by 50% or more either on that date or the previous market day. This is a way to naturally limit the information shown, as well as to focus on the companies and related news that most captured investor interest.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 54,\n            columnNumber: 1\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 54,\n            columnNumber: 7\n          }, this), \"Visualizations, charts and graphics are generated with raw data from eoddata.com and translated with custom SVG functions. All code on this site is my own.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 56,\n            columnNumber: 9\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 56,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 57,\n            columnNumber: 9\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 57,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 58,\n            columnNumber: 9\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 58,\n            columnNumber: 15\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 51,\n          columnNumber: 1\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 12,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 11,\n      columnNumber: 9\n    }, this)\n  }, void 0, false);\n}\n_c = ProjectOverview;\n\nvar _c;\n\n$RefreshReg$(_c, \"ProjectOverview\");","map":{"version":3,"sources":["/Users/josephhungate/my-app/src/ProjectOverview.js"],"names":["React","Navigate","Outlet","ProjectOverview"],"mappings":";AAAA,OAAO,WAAP;AACA,OAAOA,KAAP,MAAkB,OAAlB;AACA,SAAQC,QAAR,EAAkBC,MAAlB,QAA+B,kBAA/B;;;AAIA,eAAe,SAASC,eAAT,GAA2B;AAEtC,sBACI;AAAA,2BACA;AAAK,MAAA,SAAS,EAAC,gBAAf;AAAA,6BACA;AAAK,QAAA,SAAS,EAAC,iBAAf;AAAA,gCACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBADA,eAEA;AAAG,UAAA,SAAS,EAAC,OAAb;AAAA,6aAI4E;AAAG,YAAA,SAAS,EAAC,UAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAJ5E,8GAMA;AAAA;AAAA;AAAA;AAAA,kBANA,eAMM;AAAA;AAAA;AAAA;AAAA,kBANN,eAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAPA,mTAUA;AAAA;AAAA;AAAA;AAAA,kBAVA,eAUM;AAAA;AAAA;AAAA;AAAA,kBAVN,8BAWW;AAAG,YAAA,SAAS,EAAC,UAAb;AAAwB,YAAA,IAAI,EAAC,yBAA7B;AAAuD,YAAA,MAAM,EAAC,OAA9D;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAXX,qdAcqG;AAAG,YAAA,SAAS,EAAC,UAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAdrG,oBAeA;AAAA;AAAA;AAAA;AAAA,kBAfA,eAeM;AAAA;AAAA;AAAA;AAAA,kBAfN,qMAkBA;AAAA;AAAA;AAAA;AAAA,kBAlBA,eAkBM;AAAA;AAAA;AAAA;AAAA,kBAlBN,eAmBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAnBA,8BAoBW;AAAG,YAAA,SAAS,EAAC,UAAb;AAAwB,YAAA,IAAI,EAAC,yBAA7B;AAAuD,YAAA,MAAM,EAAC,OAA9D;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBApBX,qmBAyBA;AAAA;AAAA;AAAA;AAAA,kBAzBA,eAyBM;AAAA;AAAA;AAAA;AAAA,kBAzBN,eA0BA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBA1BA,0sBAiCA;AAAA;AAAA;AAAA;AAAA,kBAjCA,eAiCM;AAAA;AAAA;AAAA;AAAA,kBAjCN,eAkCA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAlCA,iNAoCR;AAAA;AAAA;AAAA;AAAA,kBApCQ,eAoCF;AAAA;AAAA;AAAA;AAAA,kBApCE;AAAA;AAAA;AAAA;AAAA;AAAA,gBAFA,eAuCR;AAAG,UAAA,SAAS,EAAC,QAAb;AAAA,6PACA;AAAA;AAAA;AAAA;AAAA,kBADA,eACM;AAAA;AAAA;AAAA;AAAA,kBADN,4UAGA;AAAA;AAAA;AAAA;AAAA,kBAHA,eAGM;AAAA;AAAA;AAAA;AAAA,kBAHN,8KAKQ;AAAA;AAAA;AAAA;AAAA,kBALR,eAKc;AAAA;AAAA;AAAA;AAAA,kBALd,eAMQ;AAAA;AAAA;AAAA;AAAA,kBANR,eAMc;AAAA;AAAA;AAAA;AAAA,kBANd,eAOQ;AAAA;AAAA;AAAA;AAAA,kBAPR,eAOc;AAAA;AAAA;AAAA;AAAA,kBAPd;AAAA;AAAA;AAAA;AAAA;AAAA,gBAvCQ;AAAA;AAAA;AAAA;AAAA;AAAA;AADA;AAAA;AAAA;AAAA;AAAA;AADA,mBADJ;AAwDH;KA1DuBA,e","sourcesContent":["import './App.css';\nimport React from 'react';\nimport {Navigate, Outlet} from 'react-router-dom'\n\n\n\nexport default function ProjectOverview() {\n\n    return (\n        <>\n        <div className='main-container'>\n        <div className='about-container'>\n        <h3>Inspiration</h3>\n        <p className='about'>\n        \n        During his presidency, Donald Trump was such a prolific Tweeter that specific tools were developed to analyze his tweets and alert companies when he tweeted \n        about their stock. Now, out of the 535 sitting Members of the U.S. Congress, only five have inactive Twitter accounts. What correlations can be drawn between\n        their tweets and political activities or events throughout the country? The <a className='emphasis'>Political Tweet Tool</a> aims to analyze the behavior of politicians' tweets and see\n        what conclusions can be drawn.\n        <br /><br />\n        <h2>Development</h2>\n        I began by creating a Twitter Developer account, which allowed me to utilize the Twitter API for the tweet scraping part of this project. After writing some basic Python\n        to retrieve the 535 Congress twiter handles from the House press gallery website, I was ready to start gathering data. \n        <br /><br />\n        I used the <a className='emphasis' href='https://www.tweepy.org/' target='blank'>Tweepy</a> Python library to facilitate the tweet scraping process. I \n        then integrated the Tweepy API with a custom politician data structure that would facilitate both the later SQL filtering and sentiment analysis. \n        As a web-hosted project, only twenty tweets are gathered per congressman/congresswoman in any given day range. This is to reduce loading times\n        for the end user. Larger data sets can be implemented with a direct download of this project from my <a className='emphasis'>Github</a>.\n        <br /><br />\n        The resulting dataset contains over 10,000 tweets for any selected date range,\n        which can be further filtered by name, district, state, party, time in office, retweet status, etc.\n        <br /><br />\n        <h2>Sentiment Analysis</h2>\n        I used the <a className='emphasis' href='https://www.tweepy.org/' target='blank'>VADER (Valence Aware Dictionary and sEntiment Reasoner)</a> analysis tool to establish a baseline sentiment rating for each tweet. Although\n        robust in nature, the VADER lexicon lacked certain key features necessary for an authentic tweet analysis. First, each tweet was cleaned to remove\n        superfluous text such as links and images. Next, I updated the VADER lexicon to include emojis and \"@TwitterHandle\" references. For example,\n        in the tweet \"When is @JosephHungate123 going to take responsibility for the horrible state of this website?\" it's necessary for VADER to know\n        that \"@JosephHungate123\" is a person that the tweeter is assigning blame to. \n        <br /><br />\n        <h2>Analysis</h2>\n        Analysis of the data thus far has shown some interesting results, but a much larger dataset is needed to demonstrate significance. \n        It is clear, however, that as COVID-19 progressed from March to June, the impact of financial news on market activity increased as well. \n        I am not a financial analyst – this is merely a project conducted out of curiosity – but I would expect that with more retail investors, \n        and with a market making stronger reactionary moves to both financial and non-financial news, overall market efficiency was reduced \n        slightly, leaving significant opportunity to institutional investors willing to trust emerging patterns in news, Twitter, \n        and other online activity.\n        <br /><br />\n        <h2>Notes</h2>\nThe web version of this database was developed out of a passion for digital UI and an interest in presenting somewhat complex financial information in the simplest way possible. A few notes:\n<br /><br /></p>\n<p className='indent'>The database only covers market activity (9:30 to 4), as before/after-market data is less consistent and has less retail investor activity. Only companies on the NYSE or Nasdaq exchanges are included in the dataset.\n<br /><br />\nAs a general rule, stocks are shown for a given day only if they demonstrated increased trading volume by 50% or more either on that date or the previous market day. This is a way to naturally limit the information shown, as well as to focus on the companies and related news that most captured investor interest.\n<br /><br />\nVisualizations, charts and graphics are generated with raw data from eoddata.com and translated with custom SVG functions. All code on this site is my own. \n        <br /><br />\n        <br /><br />\n        <br /><br />\n        </p>\n        </div>\n        </div>\n        </>\n    )\n\n}"]},"metadata":{},"sourceType":"module"}